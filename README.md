# ğŸ¤– LUMO - Offline AI Voice & Chat Assistant

A fully **offline AI assistant** for Windows that combines Speech-to-Text, a Local LLM, and Text-to-Speech for voice interactions, plus a text-based chat interface.

![Python](https://img.shields.io/badge/Python-3.10+-blue)
![Platform](https://img.shields.io/badge/Platform-Windows-lightgrey)
![License](https://img.shields.io/badge/License-MIT-green)

---

## âœ¨ Features

- ğŸ”‡ **100% Offline** - No internet required after setup
- ğŸ¤ **Voice Assistant** - Speak and get spoken responses
- ğŸ’¬ **Text Chat** - Type-based conversation interface
- ğŸ§  **Conversation Memory** - Remembers context across exchanges
- âš¡ **Fast Response** - Optimized for CPU inference

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        LUMO                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚   STT   â”‚â”€â”€â”€â–¶â”‚   LLM   â”‚â”€â”€â”€â–¶â”‚   TTS   â”‚                â”‚
â”‚   â”‚  VOSK   â”‚    â”‚ GPT4All â”‚    â”‚  Piper  â”‚                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚        â”‚              â”‚              â”‚                      â”‚
â”‚   Microphone     Local Model    Speaker                     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Components

### 1. Speech-to-Text (STT) - VOSK
| Property | Value |
|----------|-------|
| Library | [VOSK](https://alphacephei.com/vosk/) |
| Model | `vosk-model-small-en-us-0.15` |
| Path | `models/stt/vosk-model-small-en-us-0.15/` |
| Sample Rate | 16000 Hz |

### 2. Large Language Model (LLM) - GPT4All
| Property | Value |
|----------|-------|
| Library | [GPT4All](https://gpt4all.io/) |
| Model | `orca-mini-3b-gguf2-q4_0.gguf` |
| Path | `models/llm/orca-mini-3b-gguf2-q4_0.gguf` |
| Size | ~1.9 GB |
| Quantization | Q4_0 (4-bit) |

### 3. Text-to-Speech (TTS) - Piper
| Property | Value |
|----------|-------|
| Library | [Piper](https://github.com/rhasspy/piper) |
| Voice | `en_US-amy-medium` |
| Path | `models/tts/en_US-amy-medium.onnx` |
| Format | ONNX |

---

## ğŸ“ Project Structure

```
Lumo/
â”œâ”€â”€ main.py              # ğŸ¤ Voice assistant (STT + LLM + TTS)
â”œâ”€â”€ chat.py              # ğŸ’¬ Text chat interface
â”œâ”€â”€ test_llm.py          # ğŸ§ª LLM test script
â”œâ”€â”€ test_stt.py          # ğŸ§ª STT test script
â”œâ”€â”€ debug_main.py        # ğŸ”§ Debug version with verbose logging
â”œâ”€â”€ output.wav           # ğŸ”Š Generated TTS audio output
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ orca-mini-3b-gguf2-q4_0.gguf   # Local LLM (1.9GB)
â”‚   â”œâ”€â”€ stt/
â”‚   â”‚   â””â”€â”€ vosk-model-small-en-us-0.15/   # Speech recognition
â”‚   â””â”€â”€ tts/
â”‚       â”œâ”€â”€ en_US-amy-medium.onnx          # Voice model
â”‚       â””â”€â”€ en_US-amy-medium.onnx.json     # Voice config
â”‚
â”œâ”€â”€ piper/
â”‚   â””â”€â”€ piper/
â”‚       â””â”€â”€ piper.exe    # TTS executable
â”‚
â””â”€â”€ venv/                # Python virtual environment
```

---

## ğŸš€ Usage

### Voice Assistant
```bash
python main.py
```
- Speak into your microphone
- Say "exit", "quit", "goodbye" to stop

### Text Chat
```bash
python chat.py
```
- Type your messages
- Type "exit" or "quit" to stop

---

## ğŸ“œ Scripts Detail

### `main.py` - Voice Assistant

```python
# Key components:
from vosk import Model, KaldiRecognizer  # Speech-to-Text
from gpt4all import GPT4All              # Local LLM
import winsound                          # Audio playback
import subprocess                        # Piper TTS
```

**Flow:**
1. Captures audio via `sounddevice` at 16kHz
2. Transcribes with VOSK recognizer
3. Generates response with GPT4All (max 80 tokens)
4. Speaks using Piper TTS â†’ `output.wav` â†’ `winsound`

**Features:**
- Feedback prevention (stops listening while speaking)
- Conversation history (last 4 exchanges)
- Audio queue management

---

### `chat.py` - Text Interface

```python
# Key components:
from gpt4all import GPT4All  # Local LLM
import threading             # Async spinner
```

**Features:**
- Professional animated spinner during processing
- Conversation memory (last 2 exchanges for speed)
- Concise responses (max 80 tokens)

**Spinner Animation:**
```python
frames = ["â ‹", "â ™", "â ¹", "â ¸", "â ¼", "â ´", "â ¦", "â §", "â ‡", "â "]
```

---

## âš™ï¸ Configuration

### LLM Settings (in both main.py and chat.py)
```python
llm = GPT4All(
    model_name="orca-mini-3b-gguf2-q4_0.gguf",
    model_path="models/llm",
    allow_download=False  # Ensures offline operation
)
```

### Response Generation
```python
response = llm.generate(prompt, max_tokens=80)
```

---

## ğŸ“‹ Requirements

### Python Packages
```
gpt4all
vosk
sounddevice
```

### System Requirements
- Windows 10/11
- Python 3.10+
- Microphone (for voice mode)
- ~4GB RAM recommended

---

## ğŸ”§ Troubleshooting

### CUDA DLL Warnings
```
Failed to load llamamodel-mainline-cuda.dll
```
**This is normal!** It means GPU acceleration isn't available, so it runs on CPU instead.

### Model Not Found
Ensure the GGUF file exists at:
```
models/llm/orca-mini-3b-gguf2-q4_0.gguf
```

---

## ğŸ“ License

MIT License - Feel free to use and modify!

---

## ğŸ™ Credits

- [GPT4All](https://gpt4all.io/) - Local LLM inference
- [VOSK](https://alphacephei.com/vosk/) - Offline speech recognition
- [Piper](https://github.com/rhasspy/piper) - Neural text-to-speech
- [Orca Mini](https://huggingface.co/psmathur/orca_mini_3b) - Base LLM model
